{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules of the game\n",
    "\n",
    "- if agent tries to go off the field, punish with -10 in reward\n",
    "- if agent makes a (legal) move, punsh with -1 in reward, as we do not want to encourage endless walking around in the 10x10 grid of the environment\n",
    "- if agent tries to pick up the item, but it is not there or it has it already, punish with 10 in reward\n",
    "- if the agent picks up the item correct place, reward with 20\n",
    "- if the agent tries to drop-off item in wrong place or does not have the item, punish with 10 in reward\n",
    "- if the agent drops-off item in correct place, reward with 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Field:\n",
    "    def __init__(self, size, item_pickup, item_dropoff, start_position):\n",
    "        self.size = size\n",
    "        self.item_pickup = item_pickup\n",
    "        self.item_dropoff = item_dropoff\n",
    "        self.position = start_position\n",
    "        self.item_in_car = False\n",
    "\n",
    "    def number_of_states(self):\n",
    "        return self.size * self.size * self.size * self.size * 2\n",
    "\n",
    "    def get_state(self):\n",
    "        state = self.position[0] * self.size * self.size * self.size * 2\n",
    "        state = state + self.position[1] * self.size * self.size * 2\n",
    "        state = state + self.item_pickup[0] * self.size * 2\n",
    "        state = state + self.item_pickup[1] * 2\n",
    "        if self.item_in_car:\n",
    "            state = state + 1\n",
    "        return state\n",
    "\n",
    "    def make_action(self, action):\n",
    "        (x, y) = self.position\n",
    "        if action == 0:  # down\n",
    "            if y == self.size - 1:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x, y + 1)\n",
    "                return -1, False\n",
    "        elif action == 1:  # up\n",
    "            if y == 0:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x, y - 1)\n",
    "                return -1, False\n",
    "        elif action == 2:  # left\n",
    "            if x == 0:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x - 1, y)\n",
    "                return -1, False\n",
    "        elif action == 3:  # right\n",
    "            if x == self.size - 1:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x + 1, y)\n",
    "                return -1, False\n",
    "        elif action == 4:  # pickup\n",
    "            if self.item_in_car:\n",
    "                return -10, False\n",
    "            elif self.item_pickup != (x, y):\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.item_in_car = True\n",
    "                return 20, False\n",
    "        elif action == 5:  # dropoff\n",
    "            if not self.item_in_car:\n",
    "                return -10, False\n",
    "            elif self.item_dropoff != (x, y):\n",
    "                self.item_pickup = (x, y)\n",
    "                self.item_in_car = False\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.item_in_car = False\n",
    "                return 20, True  # Mark done as True when dropoff is successful\n",
    "        return -10, False  # Default return value to ensure a tuple is always returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "item_pickup = (0, 0)\n",
    "item_dropoff = (9, 9)\n",
    "start_position = (9, 0)\n",
    "\n",
    "field = Field(size, item_pickup, item_dropoff, start_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(9):\n",
    "    field.make_action(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.make_action(4)\n",
    "\n",
    "for _ in range(9):\n",
    "    field.make_action(0)\n",
    "\n",
    "for _ in range(9):\n",
    "    field.make_action(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.make_action(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field.item_in_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def random_solution():\n",
    "    size = 10\n",
    "    item_pickup = (0, 0)\n",
    "    item_dropoff = (9, 9)\n",
    "    start_position = (9, 0)\n",
    "\n",
    "    field = Field(size, item_pickup, item_dropoff, start_position)\n",
    "\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done:\n",
    "      action = random.randint(0,5)\n",
    "      reward, done = field.make_action(action)\n",
    "      steps += 1\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41389"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = [random_solution() for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142927.29"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(run)/len(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning\n",
    "\n",
    "- Initialize Q-table with zeros\n",
    "- Iterate\n",
    "\n",
    "  - Agent is in state State\n",
    "  - With probability epsilon choose to explore, else exploit\n",
    "    - if explore, then choose random action\n",
    "    - if exploit, then choose action based on the current Q-table\n",
    "  - Update the Q-table from the new reward to the previos state\n",
    "\n",
    "  - Q[state,action] = (1-alpha)_Q [state,action] + alpha_(reward + gamma \\* max(Q[next_state])-Q[state,action])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "size = 10\n",
    "item_pickup = (0, 0)\n",
    "item_dropoff = (9, 9)\n",
    "start_position = (9, 0)\n",
    "\n",
    "\n",
    "field = Field(size, item_pickup, item_dropoff, start_position)\n",
    "\n",
    "number_of_states = field.number_of_states()\n",
    "number_of_actions = 6\n",
    "\n",
    "q_table = np.zeros((number_of_states,number_of_actions))\n",
    "\n",
    "epsilon = 0.1\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "\n",
    "for _ in range(10000):\n",
    "    field = Field(size, item_pickup, item_dropoff, start_position)\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        state = field.get_state()\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.randint(0, 5)  # Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])  # Exploit\n",
    "\n",
    "        reward, done = field.make_action(action)\n",
    "        new_state = field.get_state()\n",
    "        new_state_max = np.max(q_table[new_state])\n",
    "\n",
    "        q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (\n",
    "            reward + gamma * new_state_max - q_table[state, action]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23071429, -2.06428571, -2.06428571,  0.23071429,  9.78571429,\n",
       "        -2.06428571],\n",
       "       [-0.71428571, -5.21428571, -5.21428571, -0.71428571, -5.21428571,\n",
       "        -2.06428571],\n",
       "       [ 1.77131848, -1.        , -1.        , -0.1       , -1.        ,\n",
       "        -1.        ],\n",
       "       ...,\n",
       "       [-1.176964  , -0.02309023, -0.21261948, -1.26446428, -0.46442451,\n",
       "        10.53735325],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REINFORCE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_learning():\n",
    "    epsilon = 0.1\n",
    "    alpha = 0.1\n",
    "    gamma = 0.6\n",
    "\n",
    "    field = Field(size, item_pickup, item_dropoff, start_position)\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done:\n",
    "        state = field.get_state()\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.randint(0, 5)  # Explore\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])  # Exploit\n",
    "\n",
    "        reward, done = field.make_action(action)\n",
    "        new_state = field.get_state()\n",
    "        new_state_max = np.max(q_table[new_state])\n",
    "\n",
    "        q_table[state, action] = (1 - alpha) * q_table[state, action] + alpha * (\n",
    "            reward + gamma * new_state_max - q_table[state, action]\n",
    "        )\n",
    "        steps += 1\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733999996681615"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPSILION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -->Explore 1 Exploit 0\n",
      "1 -->Explore 2 Exploit 0\n",
      "2 -->Explore 3 Exploit 0\n",
      "3 -->Explore 4 Exploit 0\n",
      "4 -->Explore 5 Exploit 0\n",
      "5 -->Explore 6 Exploit 0\n",
      "6 -->Explore 7 Exploit 0\n",
      "7 -->Explore 8 Exploit 0\n",
      "8 -->Explore 9 Exploit 0\n",
      "9 -->Explore 10 Exploit 0\n",
      "10 -->Explore 11 Exploit 0\n",
      "11 -->Explore 12 Exploit 0\n",
      "12 -->Explore 13 Exploit 0\n",
      "13 -->Explore 14 Exploit 0\n",
      "14 -->Explore 15 Exploit 0\n",
      "15 -->Explore 16 Exploit 0\n",
      "16 -->Explore 17 Exploit 0\n",
      "17 -->Explore 18 Exploit 0\n",
      "18 -->Explore 19 Exploit 0\n",
      "19 -->Explore 20 Exploit 0\n",
      "20 -->Explore 20 Exploit 1\n",
      "21 -->Explore 21 Exploit 1\n",
      "22 -->Explore 22 Exploit 1\n",
      "23 -->Explore 23 Exploit 1\n",
      "24 -->Explore 24 Exploit 1\n",
      "25 -->Explore 25 Exploit 1\n",
      "26 -->Explore 26 Exploit 1\n",
      "27 -->Explore 27 Exploit 1\n",
      "28 -->Explore 28 Exploit 1\n",
      "29 -->Explore 29 Exploit 1\n",
      "30 -->Explore 30 Exploit 1\n",
      "31 -->Explore 31 Exploit 1\n",
      "32 -->Explore 32 Exploit 1\n",
      "33 -->Explore 32 Exploit 2\n",
      "34 -->Explore 32 Exploit 3\n",
      "35 -->Explore 33 Exploit 3\n",
      "36 -->Explore 34 Exploit 3\n",
      "37 -->Explore 35 Exploit 3\n",
      "38 -->Explore 36 Exploit 3\n",
      "39 -->Explore 36 Exploit 4\n",
      "40 -->Explore 36 Exploit 5\n",
      "41 -->Explore 37 Exploit 5\n",
      "42 -->Explore 37 Exploit 6\n",
      "43 -->Explore 37 Exploit 7\n",
      "44 -->Explore 38 Exploit 7\n",
      "45 -->Explore 39 Exploit 7\n",
      "46 -->Explore 39 Exploit 8\n",
      "47 -->Explore 39 Exploit 9\n",
      "48 -->Explore 39 Exploit 10\n",
      "49 -->Explore 40 Exploit 10\n",
      "50 -->Explore 41 Exploit 10\n",
      "51 -->Explore 42 Exploit 10\n",
      "52 -->Explore 42 Exploit 11\n",
      "53 -->Explore 42 Exploit 12\n",
      "54 -->Explore 42 Exploit 13\n",
      "55 -->Explore 43 Exploit 13\n",
      "56 -->Explore 43 Exploit 14\n",
      "57 -->Explore 43 Exploit 15\n",
      "58 -->Explore 43 Exploit 16\n",
      "59 -->Explore 44 Exploit 16\n",
      "60 -->Explore 44 Exploit 17\n",
      "61 -->Explore 44 Exploit 18\n",
      "62 -->Explore 44 Exploit 19\n",
      "63 -->Explore 45 Exploit 19\n",
      "64 -->Explore 45 Exploit 20\n",
      "65 -->Explore 45 Exploit 21\n",
      "66 -->Explore 45 Exploit 22\n",
      "67 -->Explore 45 Exploit 23\n",
      "68 -->Explore 45 Exploit 24\n",
      "69 -->Explore 45 Exploit 25\n",
      "70 -->Explore 45 Exploit 26\n",
      "71 -->Explore 45 Exploit 27\n",
      "72 -->Explore 45 Exploit 28\n",
      "73 -->Explore 45 Exploit 29\n",
      "74 -->Explore 45 Exploit 30\n",
      "75 -->Explore 45 Exploit 31\n",
      "76 -->Explore 45 Exploit 32\n",
      "77 -->Explore 45 Exploit 33\n",
      "78 -->Explore 46 Exploit 33\n",
      "79 -->Explore 46 Exploit 34\n",
      "80 -->Explore 46 Exploit 35\n",
      "81 -->Explore 46 Exploit 36\n",
      "82 -->Explore 46 Exploit 37\n",
      "83 -->Explore 46 Exploit 38\n",
      "84 -->Explore 46 Exploit 39\n",
      "85 -->Explore 46 Exploit 40\n",
      "86 -->Explore 46 Exploit 41\n",
      "87 -->Explore 46 Exploit 42\n",
      "88 -->Explore 46 Exploit 43\n",
      "89 -->Explore 47 Exploit 43\n",
      "90 -->Explore 47 Exploit 44\n",
      "91 -->Explore 47 Exploit 45\n",
      "92 -->Explore 47 Exploit 46\n",
      "93 -->Explore 47 Exploit 47\n",
      "94 -->Explore 48 Exploit 47\n",
      "95 -->Explore 48 Exploit 48\n",
      "96 -->Explore 48 Exploit 49\n",
      "97 -->Explore 48 Exploit 50\n",
      "98 -->Explore 48 Exploit 51\n",
      "99 -->Explore 48 Exploit 52\n"
     ]
    }
   ],
   "source": [
    "ep = 1\n",
    "explore = 0\n",
    "exploit = 0\n",
    "\n",
    "for idx, i in enumerate(range(0, 100)):\n",
    "    if random.uniform(0, 1) < ep:\n",
    "        explore += 1\n",
    "    else:\n",
    "        exploit += 1\n",
    "\n",
    "    ep = ep - 0.01\n",
    "    print(idx, \"-->Explore\", explore, \"Exploit\", exploit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAMMA\n",
    "- Gamma is a discount factor\n",
    "- It is used to discount future rewards\n",
    "- range of gamma just like epsilon is between 0 and 1\n",
    "- Gamma Represents the importance of the first few steps more than the later steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPHA\n",
    "- Alpha is the learning rate\n",
    "- It is used to update the Q-table\n",
    "- range of alpha is between 0 and 1\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTINUING THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforce_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = [reinforce_learning() for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.51"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(run)/len(run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
